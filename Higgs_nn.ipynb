{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76d4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e304a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ce475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    ilayer = layers.Dense(units = 7, input_dim = len(dataset[0,:-4]), activation=\"relu\")\n",
    "    layer1 = layers.Dense(units = 8, activation=\"relu\")\n",
    "    layer2 = layers.Dense(units = 9, activation=\"relu\")\n",
    "    olayer = layers.Dense(units = 4, activation = \"sigmoid\")\n",
    "\n",
    "    Model = keras.Sequential([ilayer,layer1,layer2,olayer])\n",
    "    \n",
    "    Model.compile(\n",
    "    optimizer = keras.optimizers.SGD(0.001),\n",
    "    loss=\"binasry_crossentropy\"\n",
    "    )\n",
    "    \n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b2f9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 12:10:49.056318: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 12:10:49.062839: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-09 12:10:49.065283: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 560X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 12:10:50.692006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "''' Building the NN '''\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "fraction = 0.35\n",
    "point = int(len(dataset)*fraction)\n",
    "\n",
    "xtrain = dataset[:point,:-4]\n",
    "ytrain = dataset[:point,-4:]\n",
    "\n",
    "xtest  = dataset[point:,:-4]\n",
    "ytest  = dataset[point:,-4:]\n",
    "\n",
    "model2 = createmodel()\n",
    "\n",
    "#saving the model\n",
    "modelfolder = '/Users/dan-ioanbultoc/Desktop/EE/training/'\n",
    "\n",
    "os.path.dirname(modelfolder)\n",
    "modelsaver = tf.keras.callbacks.ModelCheckpoint(filepath = modelfolder, save_weights_only = True)\n",
    "\n",
    "''' Training the NN '''\n",
    "\n",
    "history = model2.fit(x = xtrain, y=ytrain, epochs=10, verbose = False, callbacks = [modelsaver])\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(prediction):#converts from % prediction to [0,0,1,0]\n",
    "    for i in range(len(prediction)):\n",
    "        Maxj = 0\n",
    "        for j in range(len(prediction[i])):\n",
    "            if prediction[i][j] > prediction[i][Maxj]:\n",
    "                Maxj = j       \n",
    "        prediction[i] = [0 if prediction[i][Maxj] > prediction[i][j] else 1 for j in range(len(prediction[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd90b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzemodel(model, xtestdata, ytestdata):\n",
    "    pred = model.predict(xtestdata)\n",
    "    process(pred)\n",
    "    \n",
    "    diff = abs(pred-ytestdata)\n",
    "    \n",
    "    eff = 0\n",
    "    for predict in diff:\n",
    "        eff += 1\n",
    "        for feature in predict:\n",
    "            if feature != 0:\n",
    "                eff -= 1\n",
    "                break\n",
    "    \n",
    "    eff /= len(diff)\n",
    "    return eff*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analyzemodel(model2, xtrain, ytrain))\n",
    "\n",
    "#print(ytrain[:50,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = createmodel()\n",
    "savedmodel.load_weights(modelfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ytest[0])\n",
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a398a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b885a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd_tf-metal",
   "language": "python",
   "name": "amd_tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
